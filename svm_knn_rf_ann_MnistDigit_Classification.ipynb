{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Shape:  (10000, 785)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>1x1</th>\n",
       "      <th>1x2</th>\n",
       "      <th>1x3</th>\n",
       "      <th>1x4</th>\n",
       "      <th>1x5</th>\n",
       "      <th>1x6</th>\n",
       "      <th>1x7</th>\n",
       "      <th>1x8</th>\n",
       "      <th>1x9</th>\n",
       "      <th>...</th>\n",
       "      <th>28x19</th>\n",
       "      <th>28x20</th>\n",
       "      <th>28x21</th>\n",
       "      <th>28x22</th>\n",
       "      <th>28x23</th>\n",
       "      <th>28x24</th>\n",
       "      <th>28x25</th>\n",
       "      <th>28x26</th>\n",
       "      <th>28x27</th>\n",
       "      <th>28x28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  1x1  1x2  1x3  1x4  1x5  1x6  1x7  1x8  1x9  ...  28x19  28x20  \\\n",
       "0      7    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "1      2    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "2      1    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "3      0    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "4      4    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "\n",
       "   28x21  28x22  28x23  28x24  28x25  28x26  28x27  28x28  \n",
       "0      0      0      0      0      0      0      0      0  \n",
       "1      0      0      0      0      0      0      0      0  \n",
       "2      0      0      0      0      0      0      0      0  \n",
       "3      0      0      0      0      0      0      0      0  \n",
       "4      0      0      0      0      0      0      0      0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1. Load train data set\n",
    "data=pd.read_csv(\"D:/Dataset/minstCSVDataset/mnistSmall.csv\")\n",
    "print(\"Data Shape: \",data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Columns: 785 entries, label to 28x28\n",
      "dtypes: int64(785)\n",
      "memory usage: 59.9 MB\n"
     ]
    }
   ],
   "source": [
    "# data info\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=int64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check unique label column\n",
    "np.unique(data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1135\n",
       "2    1032\n",
       "7    1028\n",
       "3    1010\n",
       "9    1009\n",
       "4     982\n",
       "0     980\n",
       "8     974\n",
       "6     958\n",
       "5     892\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count the total number of each digit count\n",
    "data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Mnist Character')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display Characters\n",
    "zero = data.iloc[1, 1:]\n",
    "zero = zero.values.reshape(28,28)\n",
    "plt.imshow(zero)\n",
    "plt.title(\"Mnist Character\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Split Dataset in Features and Traget Variables\n",
    "X=data.iloc[:,1:]\n",
    "Y=data.iloc[:,0]\n",
    "#print(\"X: \",X)\n",
    "#print(\"Y: \",Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# 3. If needed , Normalize data\n",
    "#X = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  (8000, 784)\n",
      "X_test:  (2000, 784)\n",
      "Y_train:  (8000,)\n",
      "Y_test:  (2000,)\n"
     ]
    }
   ],
   "source": [
    "# 4. Split Dataset into training and Testing sets\n",
    "Train_X,Test_X, Train_Y,Test_Y =train_test_split(X,Y,test_size=0.2,random_state=1)\n",
    "print(\"X_train: \",Train_X.shape)\n",
    "print(\"X_test: \",Test_X.shape)\n",
    "print(\"Y_train: \",Train_Y.shape)\n",
    "print(\"Y_test: \",Test_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2694    9\n",
      "5140    3\n",
      "2568    0\n",
      "3671    6\n",
      "7427    6\n",
      "       ..\n",
      "2895    8\n",
      "7813    9\n",
      "905     2\n",
      "5192    2\n",
      "235     9\n",
      "Name: label, Length: 8000, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(Train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. Define the Classifier Model\n",
    "\n",
    "# kernel{â€˜linearâ€™, â€˜polyâ€™, â€˜rbfâ€™, â€˜sigmoidâ€™, â€˜precomputedâ€™}, default=â€™rbfâ€™\n",
    "# C:Regularization parameter. default=1.0. The strength of the regularization is inversely proportional to C. \n",
    "# degreeint, default=3. Degree of the polynomial kernel function (â€˜polyâ€™). Ignored by all other kernels.\n",
    "# decision_function_shape{â€˜ovoâ€™, â€˜ovrâ€™}, default=â€™ovrâ€™\n",
    "\n",
    "model=SVC(kernel='linear', C=30.0,decision_function_shape=\"ovr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6. Train the Model\n",
    "model=model.fit(Train_X,Train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#7. Predict the response for test dataset\n",
    "ypred=model.predict(Test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.929\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score \n",
    "# 8. Print The Model Accuracy\n",
    "print(\"accuracy:\", accuracy_score(Test_Y,ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[191   0   1   1   0   2   0   0   2   0]\n",
      " [  0 220   3   2   0   0   1   0   0   0]\n",
      " [  3   2 207   2   5   2   2   1   3   1]\n",
      " [  0   0   3 188   0   1   0   1   4   1]\n",
      " [  0   0   0   1 200   1   0   0   0   2]\n",
      " [  2   1   2   6   1 136   3   2   5   1]\n",
      " [  1   1   1   0   1   2 176   0   1   0]\n",
      " [  1   2   0   2   3   0   0 206   1   5]\n",
      " [  0   4   5   4   5   4   2   0 166   2]\n",
      " [  0   2   0   1  11   1   1   8   1 168]]\n"
     ]
    }
   ],
   "source": [
    "# Print the Confusion Matrix\n",
    "#labels = ['Digit 0','Digit 1','Digit 2','Digit 3','Digit 4','Digit 5','Digit 6','Digit 7','Digit 8','Digit 9']\n",
    "print(confusion_matrix(Test_Y,ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Digit 0       0.96      0.97      0.97       197\n",
      "     Digit 1       0.95      0.97      0.96       226\n",
      "     Digit 2       0.93      0.91      0.92       228\n",
      "     Digit 3       0.91      0.95      0.93       198\n",
      "     Digit 4       0.88      0.98      0.93       204\n",
      "     Digit 5       0.91      0.86      0.88       159\n",
      "     Digit 6       0.95      0.96      0.96       183\n",
      "     Digit 7       0.94      0.94      0.94       220\n",
      "     Digit 8       0.91      0.86      0.89       192\n",
      "     Digit 9       0.93      0.87      0.90       193\n",
      "\n",
      "    accuracy                           0.93      2000\n",
      "   macro avg       0.93      0.93      0.93      2000\n",
      "weighted avg       0.93      0.93      0.93      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print the Classification Report\n",
    "target_names = ['Digit 0','Digit 1','Digit 2','Digit 3','Digit 4','Digit 5','Digit 6','Digit 7','Digit 8','Digit 9']\n",
    "print(classification_report(Test_Y, ypred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9705\n"
     ]
    }
   ],
   "source": [
    "model=SVC(kernel='rbf', C=3.0)\n",
    "model=model.fit(Train_X,Train_Y)\n",
    "ypred=model.predict(Test_X)\n",
    "print(\"accuracy:\", accuracy_score(Test_Y,ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[193   0   0   1   0   2   0   0   1   0]\n",
      " [  0 224   2   0   0   0   0   0   0   0]\n",
      " [  2   0 219   0   1   0   2   2   2   0]\n",
      " [  0   0   0 195   0   0   0   2   1   0]\n",
      " [  0   1   0   0 202   0   0   0   0   1]\n",
      " [  0   1   0   4   1 149   2   1   1   0]\n",
      " [  1   0   0   0   1   0 181   0   0   0]\n",
      " [  0   3   0   1   1   0   0 211   1   3]\n",
      " [  0   1   2   0   3   1   1   1 183   0]\n",
      " [  0   2   0   1   3   0   1   0   2 184]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(Test_Y,ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Digit 0       0.98      0.98      0.98       197\n",
      "     Digit 1       0.97      0.99      0.98       226\n",
      "     Digit 2       0.98      0.96      0.97       228\n",
      "     Digit 3       0.97      0.98      0.97       198\n",
      "     Digit 4       0.95      0.99      0.97       204\n",
      "     Digit 5       0.98      0.94      0.96       159\n",
      "     Digit 6       0.97      0.99      0.98       183\n",
      "     Digit 7       0.97      0.96      0.97       220\n",
      "     Digit 8       0.96      0.95      0.96       192\n",
      "     Digit 9       0.98      0.95      0.97       193\n",
      "\n",
      "    accuracy                           0.97      2000\n",
      "   macro avg       0.97      0.97      0.97      2000\n",
      "weighted avg       0.97      0.97      0.97      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Test_Y, ypred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.946\n"
     ]
    }
   ],
   "source": [
    "# Nearest Neighbors algorithms\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knnmodel = KNeighborsClassifier(n_neighbors=7)\n",
    "knnmodel=knnmodel.fit(Train_X,Train_Y)\n",
    "ypred=knnmodel.predict(Test_X)\n",
    "print(\"accuracy:\", accuracy_score(Test_Y,ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[194   0   0   0   0   2   1   0   0   0]\n",
      " [  0 225   1   0   0   0   0   0   0   0]\n",
      " [  6   5 206   1   0   1   1   5   2   1]\n",
      " [  0   0   0 195   0   1   0   1   0   1]\n",
      " [  0   6   0   0 189   0   0   0   0   9]\n",
      " [  0   1   0   6   0 145   4   1   0   2]\n",
      " [  0   1   0   0   0   0 182   0   0   0]\n",
      " [  0   4   1   0   1   0   0 209   0   5]\n",
      " [  0   4   4   3   3   8   0   3 166   1]\n",
      " [  0   3   0   2   4   0   1   2   0 181]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Digit 0       0.97      0.98      0.98       197\n",
      "     Digit 1       0.90      1.00      0.95       226\n",
      "     Digit 2       0.97      0.90      0.94       228\n",
      "     Digit 3       0.94      0.98      0.96       198\n",
      "     Digit 4       0.96      0.93      0.94       204\n",
      "     Digit 5       0.92      0.91      0.92       159\n",
      "     Digit 6       0.96      0.99      0.98       183\n",
      "     Digit 7       0.95      0.95      0.95       220\n",
      "     Digit 8       0.99      0.86      0.92       192\n",
      "     Digit 9       0.91      0.94      0.92       193\n",
      "\n",
      "    accuracy                           0.95      2000\n",
      "   macro avg       0.95      0.95      0.95      2000\n",
      "weighted avg       0.95      0.95      0.95      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(Test_Y,ypred))\n",
    "print(classification_report(Test_Y, ypred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.952\n"
     ]
    }
   ],
   "source": [
    "# Random forrest Classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfmodel= RandomForestClassifier(max_depth=None, random_state=0)\n",
    "rfmodel.fit(Train_X,Train_Y)\n",
    "ypred=rfmodel.predict(Test_X)\n",
    "print(\"accuracy:\", accuracy_score(Test_Y,ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Digit 0       0.98      0.98      0.98       197\n",
      "     Digit 1       0.97      0.99      0.98       226\n",
      "     Digit 2       0.95      0.93      0.94       228\n",
      "     Digit 3       0.95      0.95      0.95       198\n",
      "     Digit 4       0.94      0.97      0.95       204\n",
      "     Digit 5       0.94      0.91      0.92       159\n",
      "     Digit 6       0.96      0.98      0.97       183\n",
      "     Digit 7       0.97      0.94      0.95       220\n",
      "     Digit 8       0.93      0.93      0.93       192\n",
      "     Digit 9       0.92      0.92      0.92       193\n",
      "\n",
      "    accuracy                           0.95      2000\n",
      "   macro avg       0.95      0.95      0.95      2000\n",
      "weighted avg       0.95      0.95      0.95      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Test_Y, ypred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Shape:  (10000, 785)\n"
     ]
    }
   ],
   "source": [
    "#1. Load train data set\n",
    "data=pd.read_csv(\"D:/Dataset/minstCSVDataset/mnistSmall.csv\")\n",
    "print(\"Data Shape: \",data.shape)\n",
    "#data.head()\n",
    "X=data.iloc[:,1:]\n",
    "Y=data.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  (8000, 784)\n",
      "X_test:  (2000, 784)\n",
      "Y_train:  (8000,)\n",
      "Y_test:  (2000,)\n"
     ]
    }
   ],
   "source": [
    "# Split Dataset into training and Testing sets\n",
    "Train_X,Test_X, Train_Y,Test_Y =train_test_split(X,Y,test_size=0.2,random_state=1)\n",
    "print(\"X_train: \",Train_X.shape)\n",
    "print(\"X_test: \",Test_X.shape)\n",
    "print(\"Y_train: \",Train_Y.shape)\n",
    "print(\"Y_test: \",Test_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# define the keras model\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_dim=784, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the keras model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "# convert to one-hot vector\n",
    "Train_Y = to_categorical(Train_Y)\n",
    "Test_Y = to_categorical(Test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(Train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(Test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/256\n",
      "125/125 [==============================] - 1s 4ms/step - loss: 5.2011 - accuracy: 0.7470 - val_loss: 1.1718 - val_accuracy: 0.8735\n",
      "Epoch 2/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.7030 - accuracy: 0.9045 - val_loss: 0.7647 - val_accuracy: 0.8865\n",
      "Epoch 3/256\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.4439 - accuracy: 0.9260 - val_loss: 0.7140 - val_accuracy: 0.9020\n",
      "Epoch 4/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.2096 - accuracy: 0.9571 - val_loss: 0.8055 - val_accuracy: 0.8985\n",
      "Epoch 5/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.1415 - accuracy: 0.9672 - val_loss: 0.6835 - val_accuracy: 0.9200\n",
      "Epoch 6/256\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.1141 - accuracy: 0.9718 - val_loss: 0.6570 - val_accuracy: 0.9305\n",
      "Epoch 7/256\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.1031 - accuracy: 0.9786 - val_loss: 0.6225 - val_accuracy: 0.9215\n",
      "Epoch 8/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0985 - accuracy: 0.9793 - val_loss: 0.6317 - val_accuracy: 0.9230\n",
      "Epoch 9/256\n",
      "125/125 [==============================] - 1s 4ms/step - loss: 0.0737 - accuracy: 0.9831 - val_loss: 0.6204 - val_accuracy: 0.9300\n",
      "Epoch 10/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0582 - accuracy: 0.9845 - val_loss: 0.6770 - val_accuracy: 0.9240\n",
      "Epoch 11/256\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0718 - accuracy: 0.9814 - val_loss: 0.5657 - val_accuracy: 0.9335\n",
      "Epoch 12/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0900 - accuracy: 0.9809 - val_loss: 0.7893 - val_accuracy: 0.9265\n",
      "Epoch 13/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.1304 - accuracy: 0.9755 - val_loss: 0.7638 - val_accuracy: 0.9320\n",
      "Epoch 14/256\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.1610 - accuracy: 0.9678 - val_loss: 0.6569 - val_accuracy: 0.9260\n",
      "Epoch 15/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.1143 - accuracy: 0.9781 - val_loss: 0.6343 - val_accuracy: 0.9410\n",
      "Epoch 16/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0870 - accuracy: 0.9801 - val_loss: 0.7577 - val_accuracy: 0.9365\n",
      "Epoch 17/256\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.1402 - accuracy: 0.9766 - val_loss: 0.8163 - val_accuracy: 0.9215\n",
      "Epoch 18/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0911 - accuracy: 0.9811 - val_loss: 0.7048 - val_accuracy: 0.9245\n",
      "Epoch 19/256\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0966 - accuracy: 0.9826 - val_loss: 0.6832 - val_accuracy: 0.9430\n",
      "Epoch 20/256\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0540 - accuracy: 0.9891 - val_loss: 0.8359 - val_accuracy: 0.9305\n",
      "Epoch 21/256\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0684 - accuracy: 0.9876 - val_loss: 0.6500 - val_accuracy: 0.9435\n",
      "Epoch 22/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0607 - accuracy: 0.9889 - val_loss: 0.5419 - val_accuracy: 0.9505\n",
      "Epoch 23/256\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0530 - accuracy: 0.9893 - val_loss: 0.8380 - val_accuracy: 0.9325\n",
      "Epoch 24/256\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0834 - accuracy: 0.9862 - val_loss: 0.6777 - val_accuracy: 0.9460\n",
      "Epoch 25/256\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0895 - accuracy: 0.9845 - val_loss: 0.8252 - val_accuracy: 0.9330\n",
      "Epoch 26/256\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.1130 - accuracy: 0.9824 - val_loss: 0.6706 - val_accuracy: 0.9445\n",
      "Epoch 27/256\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0633 - accuracy: 0.9889 - val_loss: 0.8347 - val_accuracy: 0.9390\n",
      "Epoch 28/256\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0663 - accuracy: 0.9877 - val_loss: 0.6760 - val_accuracy: 0.9460\n",
      "Epoch 29/256\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0284 - accuracy: 0.9926 - val_loss: 0.5586 - val_accuracy: 0.9530\n",
      "Epoch 30/256\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0514 - accuracy: 0.9895 - val_loss: 0.7387 - val_accuracy: 0.9475\n",
      "Epoch 31/256\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0688 - accuracy: 0.9862 - val_loss: 0.7036 - val_accuracy: 0.9405\n",
      "Epoch 32/256\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0783 - accuracy: 0.9859 - val_loss: 0.6805 - val_accuracy: 0.9480\n",
      "Epoch 33/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.1216 - accuracy: 0.9805 - val_loss: 0.8287 - val_accuracy: 0.9325\n",
      "Epoch 34/256\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0959 - accuracy: 0.9841 - val_loss: 0.7121 - val_accuracy: 0.9460\n",
      "Epoch 35/256\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0582 - accuracy: 0.9891 - val_loss: 0.6165 - val_accuracy: 0.9525\n",
      "Epoch 36/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0287 - accuracy: 0.9936 - val_loss: 0.5472 - val_accuracy: 0.9540\n",
      "Epoch 37/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0231 - accuracy: 0.9936 - val_loss: 0.5631 - val_accuracy: 0.9545\n",
      "Epoch 38/256\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0374 - accuracy: 0.9936 - val_loss: 0.6695 - val_accuracy: 0.9470\n",
      "Epoch 39/256\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0199 - accuracy: 0.9948 - val_loss: 0.5296 - val_accuracy: 0.9555\n",
      "Epoch 40/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0441 - accuracy: 0.9942 - val_loss: 0.5768 - val_accuracy: 0.9550\n",
      "Epoch 41/256\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0679 - accuracy: 0.9879 - val_loss: 0.8911 - val_accuracy: 0.9370\n",
      "Epoch 42/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0927 - accuracy: 0.9847 - val_loss: 0.7616 - val_accuracy: 0.9410\n",
      "Epoch 43/256\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0782 - accuracy: 0.9859 - val_loss: 0.7892 - val_accuracy: 0.9425\n",
      "Epoch 44/256\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0659 - accuracy: 0.9884 - val_loss: 0.5641 - val_accuracy: 0.9485\n",
      "Epoch 45/256\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0360 - accuracy: 0.9939 - val_loss: 0.6034 - val_accuracy: 0.9495\n",
      "Epoch 46/256\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0175 - accuracy: 0.9969 - val_loss: 0.4732 - val_accuracy: 0.9615\n",
      "Epoch 47/256\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0171 - accuracy: 0.9965 - val_loss: 0.6026 - val_accuracy: 0.9450\n",
      "Epoch 48/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0200 - accuracy: 0.9961 - val_loss: 0.5435 - val_accuracy: 0.9535\n",
      "Epoch 49/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0278 - accuracy: 0.9954 - val_loss: 0.5611 - val_accuracy: 0.9535\n",
      "Epoch 50/256\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0255 - accuracy: 0.9939 - val_loss: 0.7132 - val_accuracy: 0.9485\n",
      "Epoch 51/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0643 - accuracy: 0.9909 - val_loss: 0.8049 - val_accuracy: 0.9440\n",
      "Epoch 52/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0689 - accuracy: 0.9902 - val_loss: 0.6312 - val_accuracy: 0.9535\n",
      "Epoch 53/256\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0862 - accuracy: 0.9872 - val_loss: 0.7567 - val_accuracy: 0.9500\n",
      "Epoch 54/256\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0626 - accuracy: 0.9900 - val_loss: 0.7836 - val_accuracy: 0.9475\n",
      "Epoch 55/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0487 - accuracy: 0.9920 - val_loss: 0.7772 - val_accuracy: 0.9440\n",
      "Epoch 56/256\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0331 - accuracy: 0.9936 - val_loss: 0.5316 - val_accuracy: 0.9575\n",
      "Epoch 57/256\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0445 - accuracy: 0.9930 - val_loss: 0.5877 - val_accuracy: 0.9525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/256\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0410 - accuracy: 0.9921 - val_loss: 0.6072 - val_accuracy: 0.9490\n",
      "Epoch 59/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0218 - accuracy: 0.9959 - val_loss: 0.5638 - val_accuracy: 0.9505\n",
      "Epoch 60/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0128 - accuracy: 0.9973 - val_loss: 0.4884 - val_accuracy: 0.9585\n",
      "Epoch 61/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0195 - accuracy: 0.9965 - val_loss: 0.5400 - val_accuracy: 0.9520\n",
      "Epoch 62/256\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0097 - accuracy: 0.9974 - val_loss: 0.6158 - val_accuracy: 0.9545\n",
      "Epoch 63/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0388 - accuracy: 0.9937 - val_loss: 0.7188 - val_accuracy: 0.9470\n",
      "Epoch 64/256\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0469 - accuracy: 0.9920 - val_loss: 0.7914 - val_accuracy: 0.9420\n",
      "Epoch 65/256\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0855 - accuracy: 0.9869 - val_loss: 0.6680 - val_accuracy: 0.9440\n",
      "Epoch 66/256\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0566 - accuracy: 0.9908 - val_loss: 0.5214 - val_accuracy: 0.9500\n",
      "Epoch 67/256\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0532 - accuracy: 0.9911 - val_loss: 0.6106 - val_accuracy: 0.9470\n",
      "Epoch 68/256\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0254 - accuracy: 0.9951 - val_loss: 0.5308 - val_accuracy: 0.9525\n",
      "Epoch 69/256\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0161 - accuracy: 0.9965 - val_loss: 0.4946 - val_accuracy: 0.9580\n",
      "Epoch 70/256\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0120 - accuracy: 0.9974 - val_loss: 0.5517 - val_accuracy: 0.9560\n",
      "Epoch 71/256\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0062 - accuracy: 0.9990 - val_loss: 0.5490 - val_accuracy: 0.9560\n",
      "Epoch 72/256\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0174 - accuracy: 0.9967 - val_loss: 0.5921 - val_accuracy: 0.9530\n",
      "Epoch 73/256\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0159 - accuracy: 0.9975 - val_loss: 0.5258 - val_accuracy: 0.9540\n",
      "Epoch 74/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0087 - accuracy: 0.9984 - val_loss: 0.5448 - val_accuracy: 0.9575\n",
      "Epoch 75/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0148 - accuracy: 0.9975 - val_loss: 0.5785 - val_accuracy: 0.9500\n",
      "Epoch 76/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0043 - accuracy: 0.9985 - val_loss: 0.5716 - val_accuracy: 0.9525\n",
      "Epoch 77/256\n",
      "125/125 [==============================] - 1s 4ms/step - loss: 0.0087 - accuracy: 0.9977 - val_loss: 0.6625 - val_accuracy: 0.9535\n",
      "Epoch 78/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0162 - accuracy: 0.9962 - val_loss: 0.6831 - val_accuracy: 0.9530\n",
      "Epoch 79/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0559 - accuracy: 0.9901 - val_loss: 0.7983 - val_accuracy: 0.9445\n",
      "Epoch 80/256\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 0.0840 - accuracy: 0.9879 - val_loss: 0.5279 - val_accuracy: 0.9465\n",
      "Epoch 81/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0375 - accuracy: 0.9925 - val_loss: 0.7483 - val_accuracy: 0.9475\n",
      "Epoch 82/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0437 - accuracy: 0.9931 - val_loss: 0.6134 - val_accuracy: 0.9545\n",
      "Epoch 83/256\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0149 - accuracy: 0.9966 - val_loss: 0.5616 - val_accuracy: 0.9525\n",
      "Epoch 84/256\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.5533 - val_accuracy: 0.9550\n",
      "Epoch 85/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0063 - accuracy: 0.9987 - val_loss: 0.5832 - val_accuracy: 0.9545\n",
      "Epoch 86/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.0050 - accuracy: 0.9987 - val_loss: 0.4905 - val_accuracy: 0.9545\n",
      "Epoch 87/256\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.0027 - accuracy: 0.99 - 0s 2ms/step - loss: 0.0025 - accuracy: 0.9996 - val_loss: 0.4741 - val_accuracy: 0.9580\n",
      "Epoch 88/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 2.1727e-04 - accuracy: 1.0000 - val_loss: 0.4367 - val_accuracy: 0.9600\n",
      "Epoch 89/256\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 3.2338e-05 - accuracy: 1.0000 - val_loss: 0.4380 - val_accuracy: 0.9605\n",
      "Epoch 90/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 2.1744e-05 - accuracy: 1.0000 - val_loss: 0.4388 - val_accuracy: 0.9610\n",
      "Epoch 91/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 1.7475e-05 - accuracy: 1.0000 - val_loss: 0.4390 - val_accuracy: 0.9610\n",
      "Epoch 92/256\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.4845e-05 - accuracy: 1.0000 - val_loss: 0.4395 - val_accuracy: 0.9610\n",
      "Epoch 93/256\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.2949e-05 - accuracy: 1.0000 - val_loss: 0.4400 - val_accuracy: 0.9610\n",
      "Epoch 94/256\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.1501e-05 - accuracy: 1.0000 - val_loss: 0.4403 - val_accuracy: 0.9615\n",
      "Epoch 95/256\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.0179e-05 - accuracy: 1.0000 - val_loss: 0.4408 - val_accuracy: 0.9615\n",
      "Epoch 96/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 9.1933e-06 - accuracy: 1.0000 - val_loss: 0.4413 - val_accuracy: 0.9615\n",
      "Epoch 97/256\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 8.3566e-06 - accuracy: 1.0000 - val_loss: 0.4417 - val_accuracy: 0.9615\n",
      "Epoch 98/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 7.6543e-06 - accuracy: 1.0000 - val_loss: 0.4421 - val_accuracy: 0.9620\n",
      "Epoch 99/256\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 7.0358e-06 - accuracy: 1.0000 - val_loss: 0.4425 - val_accuracy: 0.9620\n",
      "Epoch 100/256\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 6.4987e-06 - accuracy: 1.0000 - val_loss: 0.4429 - val_accuracy: 0.9615\n",
      "Epoch 101/256\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 6.0188e-06 - accuracy: 1.0000 - val_loss: 0.4433 - val_accuracy: 0.9615\n",
      "Epoch 102/256\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 5.5882e-06 - accuracy: 1.0000 - val_loss: 0.4437 - val_accuracy: 0.9615\n",
      "Epoch 103/256\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 5.1845e-06 - accuracy: 1.0000 - val_loss: 0.4441 - val_accuracy: 0.9610\n",
      "Epoch 104/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 4.8231e-06 - accuracy: 1.0000 - val_loss: 0.4444 - val_accuracy: 0.9610\n",
      "Epoch 105/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 4.4938e-06 - accuracy: 1.0000 - val_loss: 0.4448 - val_accuracy: 0.9605\n",
      "Epoch 106/256\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 4.1953e-06 - accuracy: 1.0000 - val_loss: 0.4451 - val_accuracy: 0.9605\n",
      "Epoch 107/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 3.9191e-06 - accuracy: 1.0000 - val_loss: 0.4455 - val_accuracy: 0.9605\n",
      "Epoch 108/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 3.6694e-06 - accuracy: 1.0000 - val_loss: 0.4459 - val_accuracy: 0.9605\n",
      "Epoch 109/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 3.4333e-06 - accuracy: 1.0000 - val_loss: 0.4462 - val_accuracy: 0.9605\n",
      "Epoch 110/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 3.2165e-06 - accuracy: 1.0000 - val_loss: 0.4466 - val_accuracy: 0.9605\n",
      "Epoch 111/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 3.0211e-06 - accuracy: 1.0000 - val_loss: 0.4469 - val_accuracy: 0.9605\n",
      "Epoch 112/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 2.8315e-06 - accuracy: 1.0000 - val_loss: 0.4473 - val_accuracy: 0.9610\n",
      "Epoch 113/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 2.6596e-06 - accuracy: 1.0000 - val_loss: 0.4477 - val_accuracy: 0.9610\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 114/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 2.5009e-06 - accuracy: 1.0000 - val_loss: 0.4481 - val_accuracy: 0.9610\n",
      "Epoch 115/256\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 2.3517e-06 - accuracy: 1.0000 - val_loss: 0.4485 - val_accuracy: 0.9610\n",
      "Epoch 116/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 2.2137e-06 - accuracy: 1.0000 - val_loss: 0.4488 - val_accuracy: 0.9610\n",
      "Epoch 117/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 2.0828e-06 - accuracy: 1.0000 - val_loss: 0.4492 - val_accuracy: 0.9610\n",
      "Epoch 118/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 1.9546e-06 - accuracy: 1.0000 - val_loss: 0.4497 - val_accuracy: 0.9605\n",
      "Epoch 119/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 1.8359e-06 - accuracy: 1.0000 - val_loss: 0.4501 - val_accuracy: 0.9605\n",
      "Epoch 120/256\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 1.7264e-06 - accuracy: 1.0000 - val_loss: 0.4506 - val_accuracy: 0.9605\n",
      "Epoch 121/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 1.6270e-06 - accuracy: 1.0000 - val_loss: 0.4510 - val_accuracy: 0.9605\n",
      "Epoch 122/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 1.5321e-06 - accuracy: 1.0000 - val_loss: 0.4513 - val_accuracy: 0.9605\n",
      "Epoch 123/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 1.4450e-06 - accuracy: 1.0000 - val_loss: 0.4517 - val_accuracy: 0.9605\n",
      "Epoch 124/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 1.3624e-06 - accuracy: 1.0000 - val_loss: 0.4522 - val_accuracy: 0.9605\n",
      "Epoch 125/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 1.2844e-06 - accuracy: 1.0000 - val_loss: 0.4526 - val_accuracy: 0.9610\n",
      "Epoch 126/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 1.2109e-06 - accuracy: 1.0000 - val_loss: 0.4530 - val_accuracy: 0.9610\n",
      "Epoch 127/256\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 1.1405e-06 - accuracy: 1.0000 - val_loss: 0.4534 - val_accuracy: 0.9610\n",
      "Epoch 128/256\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 1.0749e-06 - accuracy: 1.0000 - val_loss: 0.4539 - val_accuracy: 0.9615\n",
      "Epoch 129/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 1.0125e-06 - accuracy: 1.0000 - val_loss: 0.4543 - val_accuracy: 0.9615\n",
      "Epoch 130/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 9.5461e-07 - accuracy: 1.0000 - val_loss: 0.4548 - val_accuracy: 0.9615\n",
      "Epoch 131/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 8.9839e-07 - accuracy: 1.0000 - val_loss: 0.4552 - val_accuracy: 0.9615\n",
      "Epoch 132/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 8.4757e-07 - accuracy: 1.0000 - val_loss: 0.4556 - val_accuracy: 0.9615\n",
      "Epoch 133/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 7.9844e-07 - accuracy: 1.0000 - val_loss: 0.4562 - val_accuracy: 0.9615\n",
      "Epoch 134/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 7.5191e-07 - accuracy: 1.0000 - val_loss: 0.4567 - val_accuracy: 0.9615\n",
      "Epoch 135/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 7.0749e-07 - accuracy: 1.0000 - val_loss: 0.4571 - val_accuracy: 0.9615\n",
      "Epoch 136/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 6.6645e-07 - accuracy: 1.0000 - val_loss: 0.4575 - val_accuracy: 0.9615\n",
      "Epoch 137/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 6.2806e-07 - accuracy: 1.0000 - val_loss: 0.4580 - val_accuracy: 0.9615\n",
      "Epoch 138/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 5.9161e-07 - accuracy: 1.0000 - val_loss: 0.4585 - val_accuracy: 0.9615\n",
      "Epoch 139/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 5.5826e-07 - accuracy: 1.0000 - val_loss: 0.4590 - val_accuracy: 0.9620\n",
      "Epoch 140/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 5.2603e-07 - accuracy: 1.0000 - val_loss: 0.4594 - val_accuracy: 0.9620\n",
      "Epoch 141/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 4.9554e-07 - accuracy: 1.0000 - val_loss: 0.4600 - val_accuracy: 0.9620\n",
      "Epoch 142/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 4.6694e-07 - accuracy: 1.0000 - val_loss: 0.4605 - val_accuracy: 0.9620\n",
      "Epoch 143/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 4.4032e-07 - accuracy: 1.0000 - val_loss: 0.4609 - val_accuracy: 0.9620\n",
      "Epoch 144/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 4.1495e-07 - accuracy: 1.0000 - val_loss: 0.4615 - val_accuracy: 0.9615\n",
      "Epoch 145/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 3.9111e-07 - accuracy: 1.0000 - val_loss: 0.4620 - val_accuracy: 0.9615\n",
      "Epoch 146/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 3.6804e-07 - accuracy: 1.0000 - val_loss: 0.4626 - val_accuracy: 0.9615\n",
      "Epoch 147/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 3.4631e-07 - accuracy: 1.0000 - val_loss: 0.4630 - val_accuracy: 0.9615\n",
      "Epoch 148/256\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 3.2635e-07 - accuracy: 1.0000 - val_loss: 0.4635 - val_accuracy: 0.9615\n",
      "Epoch 149/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 3.0678e-07 - accuracy: 1.0000 - val_loss: 0.4641 - val_accuracy: 0.9615\n",
      "Epoch 150/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 2.8848e-07 - accuracy: 1.0000 - val_loss: 0.4647 - val_accuracy: 0.9615\n",
      "Epoch 151/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 2.7114e-07 - accuracy: 1.0000 - val_loss: 0.4651 - val_accuracy: 0.9615\n",
      "Epoch 152/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 2.5546e-07 - accuracy: 1.0000 - val_loss: 0.4657 - val_accuracy: 0.9615\n",
      "Epoch 153/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 2.4020e-07 - accuracy: 1.0000 - val_loss: 0.4663 - val_accuracy: 0.9615\n",
      "Epoch 154/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 2.2608e-07 - accuracy: 1.0000 - val_loss: 0.4668 - val_accuracy: 0.9620\n",
      "Epoch 155/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 2.1274e-07 - accuracy: 1.0000 - val_loss: 0.4674 - val_accuracy: 0.9620\n",
      "Epoch 156/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 1.9996e-07 - accuracy: 1.0000 - val_loss: 0.4680 - val_accuracy: 0.9620\n",
      "Epoch 157/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 1.8817e-07 - accuracy: 1.0000 - val_loss: 0.4685 - val_accuracy: 0.9620\n",
      "Epoch 158/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 1.7653e-07 - accuracy: 1.0000 - val_loss: 0.4691 - val_accuracy: 0.9620\n",
      "Epoch 159/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 1.6600e-07 - accuracy: 1.0000 - val_loss: 0.4696 - val_accuracy: 0.9625\n",
      "Epoch 160/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 1.5640e-07 - accuracy: 1.0000 - val_loss: 0.4702 - val_accuracy: 0.9625\n",
      "Epoch 161/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 1.4724e-07 - accuracy: 1.0000 - val_loss: 0.4708 - val_accuracy: 0.9625\n",
      "Epoch 162/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 1.3812e-07 - accuracy: 1.0000 - val_loss: 0.4714 - val_accuracy: 0.9625\n",
      "Epoch 163/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 1.3007e-07 - accuracy: 1.0000 - val_loss: 0.4720 - val_accuracy: 0.9625\n",
      "Epoch 164/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 1.2189e-07 - accuracy: 1.0000 - val_loss: 0.4727 - val_accuracy: 0.9625\n",
      "Epoch 165/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 1.1463e-07 - accuracy: 1.0000 - val_loss: 0.4730 - val_accuracy: 0.9620\n",
      "Epoch 166/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 1.0763e-07 - accuracy: 1.0000 - val_loss: 0.4737 - val_accuracy: 0.9620\n",
      "Epoch 167/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 1.0116e-07 - accuracy: 1.0000 - val_loss: 0.4743 - val_accuracy: 0.9620\n",
      "Epoch 168/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 9.5188e-08 - accuracy: 1.0000 - val_loss: 0.4748 - val_accuracy: 0.9625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 8.9600e-08 - accuracy: 1.0000 - val_loss: 0.4754 - val_accuracy: 0.9625\n",
      "Epoch 170/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 8.4057e-08 - accuracy: 1.0000 - val_loss: 0.4760 - val_accuracy: 0.9625\n",
      "Epoch 171/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 7.9200e-08 - accuracy: 1.0000 - val_loss: 0.4767 - val_accuracy: 0.9625\n",
      "Epoch 172/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 7.4684e-08 - accuracy: 1.0000 - val_loss: 0.4772 - val_accuracy: 0.9625\n",
      "Epoch 173/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 7.0229e-08 - accuracy: 1.0000 - val_loss: 0.4778 - val_accuracy: 0.9625\n",
      "Epoch 174/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 6.6116e-08 - accuracy: 1.0000 - val_loss: 0.4785 - val_accuracy: 0.9625\n",
      "Epoch 175/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 6.1989e-08 - accuracy: 1.0000 - val_loss: 0.4790 - val_accuracy: 0.9625\n",
      "Epoch 176/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 5.8427e-08 - accuracy: 1.0000 - val_loss: 0.4796 - val_accuracy: 0.9625\n",
      "Epoch 177/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 5.5089e-08 - accuracy: 1.0000 - val_loss: 0.4803 - val_accuracy: 0.9630\n",
      "Epoch 178/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 5.1916e-08 - accuracy: 1.0000 - val_loss: 0.4810 - val_accuracy: 0.9630\n",
      "Epoch 179/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 4.8682e-08 - accuracy: 1.0000 - val_loss: 0.4816 - val_accuracy: 0.9630\n",
      "Epoch 180/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 4.5747e-08 - accuracy: 1.0000 - val_loss: 0.4821 - val_accuracy: 0.9630\n",
      "Epoch 181/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 4.3049e-08 - accuracy: 1.0000 - val_loss: 0.4827 - val_accuracy: 0.9630\n",
      "Epoch 182/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 4.0531e-08 - accuracy: 1.0000 - val_loss: 0.4834 - val_accuracy: 0.9630\n",
      "Epoch 183/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 3.7953e-08 - accuracy: 1.0000 - val_loss: 0.4840 - val_accuracy: 0.9630\n",
      "Epoch 184/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 3.5778e-08 - accuracy: 1.0000 - val_loss: 0.4847 - val_accuracy: 0.9630\n",
      "Epoch 185/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 3.3483e-08 - accuracy: 1.0000 - val_loss: 0.4854 - val_accuracy: 0.9630\n",
      "Epoch 186/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 3.1605e-08 - accuracy: 1.0000 - val_loss: 0.4860 - val_accuracy: 0.9630\n",
      "Epoch 187/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 2.9549e-08 - accuracy: 1.0000 - val_loss: 0.4866 - val_accuracy: 0.9630\n",
      "Epoch 188/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 2.7761e-08 - accuracy: 1.0000 - val_loss: 0.4873 - val_accuracy: 0.9630\n",
      "Epoch 189/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 2.6256e-08 - accuracy: 1.0000 - val_loss: 0.4880 - val_accuracy: 0.9630\n",
      "Epoch 190/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 2.4706e-08 - accuracy: 1.0000 - val_loss: 0.4885 - val_accuracy: 0.9635\n",
      "Epoch 191/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 2.3216e-08 - accuracy: 1.0000 - val_loss: 0.4892 - val_accuracy: 0.9635\n",
      "Epoch 192/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 2.1741e-08 - accuracy: 1.0000 - val_loss: 0.4897 - val_accuracy: 0.9635\n",
      "Epoch 193/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 2.0489e-08 - accuracy: 1.0000 - val_loss: 0.4904 - val_accuracy: 0.9635\n",
      "Epoch 194/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 1.9193e-08 - accuracy: 1.0000 - val_loss: 0.4908 - val_accuracy: 0.9635\n",
      "Epoch 195/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 1.8224e-08 - accuracy: 1.0000 - val_loss: 0.4915 - val_accuracy: 0.9635\n",
      "Epoch 196/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 1.7062e-08 - accuracy: 1.0000 - val_loss: 0.4921 - val_accuracy: 0.9635\n",
      "Epoch 197/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 1.5900e-08 - accuracy: 1.0000 - val_loss: 0.4926 - val_accuracy: 0.9635\n",
      "Epoch 198/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 1.4901e-08 - accuracy: 1.0000 - val_loss: 0.4933 - val_accuracy: 0.9635\n",
      "Epoch 199/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 1.3977e-08 - accuracy: 1.0000 - val_loss: 0.4939 - val_accuracy: 0.9635\n",
      "Epoch 200/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 1.3366e-08 - accuracy: 1.0000 - val_loss: 0.4946 - val_accuracy: 0.9635\n",
      "Epoch 201/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 1.2383e-08 - accuracy: 1.0000 - val_loss: 0.4951 - val_accuracy: 0.9635\n",
      "Epoch 202/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 1.1608e-08 - accuracy: 1.0000 - val_loss: 0.4956 - val_accuracy: 0.9635\n",
      "Epoch 203/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 1.0997e-08 - accuracy: 1.0000 - val_loss: 0.4962 - val_accuracy: 0.9635\n",
      "Epoch 204/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 1.0237e-08 - accuracy: 1.0000 - val_loss: 0.4967 - val_accuracy: 0.9635\n",
      "Epoch 205/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 9.7305e-09 - accuracy: 1.0000 - val_loss: 0.4974 - val_accuracy: 0.9635\n",
      "Epoch 206/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 9.1791e-09 - accuracy: 1.0000 - val_loss: 0.4981 - val_accuracy: 0.9635\n",
      "Epoch 207/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 8.6278e-09 - accuracy: 1.0000 - val_loss: 0.4988 - val_accuracy: 0.9635\n",
      "Epoch 208/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 8.1360e-09 - accuracy: 1.0000 - val_loss: 0.4994 - val_accuracy: 0.9635\n",
      "Epoch 209/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 7.6294e-09 - accuracy: 1.0000 - val_loss: 0.5002 - val_accuracy: 0.9635\n",
      "Epoch 210/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 7.1824e-09 - accuracy: 1.0000 - val_loss: 0.5007 - val_accuracy: 0.9635\n",
      "Epoch 211/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 6.7502e-09 - accuracy: 1.0000 - val_loss: 0.5011 - val_accuracy: 0.9635\n",
      "Epoch 212/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 6.2436e-09 - accuracy: 1.0000 - val_loss: 0.5015 - val_accuracy: 0.9635\n",
      "Epoch 213/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 5.9605e-09 - accuracy: 1.0000 - val_loss: 0.5019 - val_accuracy: 0.9635\n",
      "Epoch 214/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 5.6177e-09 - accuracy: 1.0000 - val_loss: 0.5023 - val_accuracy: 0.9635\n",
      "Epoch 215/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 5.2750e-09 - accuracy: 1.0000 - val_loss: 0.5026 - val_accuracy: 0.9635\n",
      "Epoch 216/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 4.9323e-09 - accuracy: 1.0000 - val_loss: 0.5030 - val_accuracy: 0.9635\n",
      "Epoch 217/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 4.6045e-09 - accuracy: 1.0000 - val_loss: 0.5032 - val_accuracy: 0.9635\n",
      "Epoch 218/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 4.4256e-09 - accuracy: 1.0000 - val_loss: 0.5035 - val_accuracy: 0.9630\n",
      "Epoch 219/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 4.1276e-09 - accuracy: 1.0000 - val_loss: 0.5037 - val_accuracy: 0.9630\n",
      "Epoch 220/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 3.8147e-09 - accuracy: 1.0000 - val_loss: 0.5036 - val_accuracy: 0.9625\n",
      "Epoch 221/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 3.5465e-09 - accuracy: 1.0000 - val_loss: 0.5035 - val_accuracy: 0.9620\n",
      "Epoch 222/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 3.3677e-09 - accuracy: 1.0000 - val_loss: 0.5034 - val_accuracy: 0.9620\n",
      "Epoch 223/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 3.3081e-09 - accuracy: 1.0000 - val_loss: 0.5033 - val_accuracy: 0.9625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 224/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 3.1292e-09 - accuracy: 1.0000 - val_loss: 0.5031 - val_accuracy: 0.9630\n",
      "Epoch 225/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 2.8610e-09 - accuracy: 1.0000 - val_loss: 0.5029 - val_accuracy: 0.9630\n",
      "Epoch 226/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 2.8014e-09 - accuracy: 1.0000 - val_loss: 0.5032 - val_accuracy: 0.9630\n",
      "Epoch 227/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 2.5779e-09 - accuracy: 1.0000 - val_loss: 0.5031 - val_accuracy: 0.9630\n",
      "Epoch 228/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 2.4885e-09 - accuracy: 1.0000 - val_loss: 0.5028 - val_accuracy: 0.9630\n",
      "Epoch 229/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 2.3544e-09 - accuracy: 1.0000 - val_loss: 0.5031 - val_accuracy: 0.9630\n",
      "Epoch 230/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 2.3246e-09 - accuracy: 1.0000 - val_loss: 0.5027 - val_accuracy: 0.9630\n",
      "Epoch 231/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 2.0862e-09 - accuracy: 1.0000 - val_loss: 0.5027 - val_accuracy: 0.9630\n",
      "Epoch 232/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 2.0117e-09 - accuracy: 1.0000 - val_loss: 0.5023 - val_accuracy: 0.9630\n",
      "Epoch 233/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 1.8924e-09 - accuracy: 1.0000 - val_loss: 0.5018 - val_accuracy: 0.9630\n",
      "Epoch 234/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 1.8179e-09 - accuracy: 1.0000 - val_loss: 0.5010 - val_accuracy: 0.9635\n",
      "Epoch 235/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 1.7881e-09 - accuracy: 1.0000 - val_loss: 0.5005 - val_accuracy: 0.9635\n",
      "Epoch 236/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 1.6838e-09 - accuracy: 1.0000 - val_loss: 0.4999 - val_accuracy: 0.9635\n",
      "Epoch 237/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 1.6689e-09 - accuracy: 1.0000 - val_loss: 0.4991 - val_accuracy: 0.9635\n",
      "Epoch 238/256\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.5944e-09 - accuracy: 1.0000 - val_loss: 0.4984 - val_accuracy: 0.9635\n",
      "Epoch 239/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 1.5795e-09 - accuracy: 1.0000 - val_loss: 0.4980 - val_accuracy: 0.9640\n",
      "Epoch 240/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 1.4305e-09 - accuracy: 1.0000 - val_loss: 0.4969 - val_accuracy: 0.9640\n",
      "Epoch 241/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 1.5050e-09 - accuracy: 1.0000 - val_loss: 0.4960 - val_accuracy: 0.9640\n",
      "Epoch 242/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 1.4305e-09 - accuracy: 1.0000 - val_loss: 0.4959 - val_accuracy: 0.9640\n",
      "Epoch 243/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 1.4454e-09 - accuracy: 1.0000 - val_loss: 0.4951 - val_accuracy: 0.9640\n",
      "Epoch 244/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 1.2666e-09 - accuracy: 1.0000 - val_loss: 0.4940 - val_accuracy: 0.9640\n",
      "Epoch 245/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 1.3411e-09 - accuracy: 1.0000 - val_loss: 0.4929 - val_accuracy: 0.9640\n",
      "Epoch 246/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 1.3113e-09 - accuracy: 1.0000 - val_loss: 0.4916 - val_accuracy: 0.9645\n",
      "Epoch 247/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 1.2219e-09 - accuracy: 1.0000 - val_loss: 0.4904 - val_accuracy: 0.9650\n",
      "Epoch 248/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 1.2368e-09 - accuracy: 1.0000 - val_loss: 0.4892 - val_accuracy: 0.9650\n",
      "Epoch 249/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 1.2517e-09 - accuracy: 1.0000 - val_loss: 0.4888 - val_accuracy: 0.9650\n",
      "Epoch 250/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 1.1325e-09 - accuracy: 1.0000 - val_loss: 0.4872 - val_accuracy: 0.9640\n",
      "Epoch 251/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 1.2964e-09 - accuracy: 1.0000 - val_loss: 0.4858 - val_accuracy: 0.9640\n",
      "Epoch 252/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 1.2070e-09 - accuracy: 1.0000 - val_loss: 0.4848 - val_accuracy: 0.9645\n",
      "Epoch 253/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 1.1474e-09 - accuracy: 1.0000 - val_loss: 0.4843 - val_accuracy: 0.9645\n",
      "Epoch 254/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 1.1921e-09 - accuracy: 1.0000 - val_loss: 0.4829 - val_accuracy: 0.9640\n",
      "Epoch 255/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 1.1176e-09 - accuracy: 1.0000 - val_loss: 0.4809 - val_accuracy: 0.9645\n",
      "Epoch 256/256\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 1.1772e-09 - accuracy: 1.0000 - val_loss: 0.4799 - val_accuracy: 0.9645\n"
     ]
    }
   ],
   "source": [
    "# fit the keras model on the dataset\n",
    "History=model.fit(Train_X,Train_Y,validation_data=(Test_X, Test_Y), epochs=256, batch_size=64,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 100.00\n"
     ]
    }
   ],
   "source": [
    "# evaluate the keras model\n",
    "_, train_acc = model.evaluate(Train_X, Train_Y, verbose=0)\n",
    "print('Training Accuracy: %.2f' % (train_acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    }
   ],
   "source": [
    "print(History.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(History.history['accuracy'])\n",
    "plt.plot(History.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for loss\n",
    "plt.plot(History.history['loss'])\n",
    "plt.plot(History.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
